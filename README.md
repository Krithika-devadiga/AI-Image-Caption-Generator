# 🧠 AI Image Captioning Web App

This project is a Flask-based web application that uses a Transformer-based deep learning model to generate **automatic captions for images**. Upload any image, and get a meaningful caption generated by

## ✨ Features

- 📷 Upload image through a simple UI
- 🧠 Generates intelligent image captions using Transformers
- 🔊 Uses pre-trained models from Hugging Face (`blip-image-captioning-base`)
- 🌐 Web interface built with HTML, CSS, and Flask
- 📦 Lightweight and easy to deploy

---

## 🚀 Technologies Used

| Tool        | Purpose                                  |
|-------------|------------------------------------------|
| **Flask**   | Web backend framework (Python)           |
| **Torch**   | PyTorch for model inference              |
| **Transformers** | Pretrained Hugging Face captioning model |
| **Pillow**  | Image processing in Python               |
| **HTML/CSS**| Web front-end                            |

---


## 📁 Project Structure

- `flask-captioner/`: Contains the Flask backend files including the deep learning model, captioning logic, and the main app file (app.py).

- `index.html`: The main HTML frontend for uploading images and displaying AI-generated captions.

- `style.css`: CSS file used for UI design and animated background effects to enhance user experience.

- `script.js`: (Optional) JavaScript file for adding interactivity to the frontend.

- `.gitignore`: Specifies files and folders (like __pycache__ or large model files) to be excluded from version control.

- `README.md`: This documentation file that describes the project’s purpose, setup steps, and usage instructions.

---

## 🖼️ How It Works

1. User uploads an image through the form.
2. Flask handles the image backend and loads the model.
3. Model processes the image and generates a caption.
4. Caption is displayed on the web page below the image.

---

## 🛠️ Setup Instructions

1. **Clone this repository**
 
git clone https://github.com/yourusername/ai-image-captioning.git
cd ai-image-captioning


2. **Create and activate virtual environment**
python -m venv venv
source venv/bin/activate  # for Linux/Mac
venv\Scripts\activate     # for Windows

3. **Install dependencies**
pip install flask torch transformers pillow

4. **Run the app**
python app.py

5. **Visit in browser**
http://127.0.0.1:5000

---

## 🧠 Model Used
* BLIP Image Captioning Model
* Pretrained on a large dataset of image-text pairs
* Available via Hugging Face transformers library